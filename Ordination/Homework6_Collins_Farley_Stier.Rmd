---
title: "S&DS 363 Homework 6"
author: "Evan Collins, Kelly Farley, Ken Stier"
date: "23 April 2021"
output:
  html_document:
   toc: yes
   toc_float:
     collapsed: no
  pdf_document:
    latex_engine : xelatex
---

```{r, message=F, warning=F}
# clear env
rm(list=ls())

# Load packages
library(car)
library(tidyverse)
library(MASS)
library(DiscriMiner)
library(klaR)
#library(aplpack)
library(fpc)
library(cluster)
library(ape)
library(amap)

# Packages pertinent to Ordination
library(vegan) # eggplant
library(vegan3d)
library(mgcv)
library(rgl)
library(dplyr)
library(magrittr)
```

# Contributors

Evan Collins (evan.collins@yale.edu)

Kelly Farley (kelly.farley@yale.edu)

Ken Stier (ken.stier@yale.edu)

# The Dataset

*Raw dataset:*
COVID-19 infection and death statistics from U.S. counties (sourced from NYT), combined with economic, education, and population data (sourced from various government agencies) and also survey responses about mask-wearing frequencies (sourced from NYT). 3141 complete observations on 19 metric variables and 6 categorical variables. To avoid any outliers due to population size differences between counties, all variables are scaled as a percentage of population. Variable descriptions can be found [here](http://evancollins.com/variable_descriptions.html).

*Data of relevance for this pset:*

This pset only explores the 67 counties in the best state, Florida.

We look at five continuous variables describing each county: `Always_Wear_Mask_Survey`, `Median_Household_Income_Percent_of_State_Total_2019`, `Percent_Poverty_2019`, `Percent_Adults_Less_Than_HS`, and `Covid_Confirmed_Cases_as_pct`. Note that `Always_Wear_Mask_Survey` and `Covid_Confirmed_Cases_as_pct` were multiplied by 100 to convert the value from a fraction to percent value (like the other variables). This data is stored in `data_ord_base`.

For additional continuous variables, we make an environmental dataset. We look at five additional continuous variables describing each county: `Unemployment_Rate_2019`, `Death_Rate_2019`, `Birth_Rate_2019`, `Civilian_Labor_Force_2019_as_pct`, `Percent_Adults_Bachelors_or_Higher`. Note that `Civilian_Labor_Force_2019_as_pct` was multiplied by 100 to convert the value from a fraction to percent value (like the other variables). This data is stored in `data_ord_env`.


```{r}
# Process raw dataset as we have done in preceding psets

raw <- read.csv("https://evancollins.com/covid_and_demographics.csv")

# create categorical variables: rural-urban code (3 levels), region (4 variables)

# log transformations of our continuous variables
raw$logMedian_Household_Income_2019 <- log(raw$Median_Household_Income_2019 + 0.0001)
raw$logPercent_Poverty_2019 <- log(raw$Percent_Poverty_2019 + 0.0001)
raw$logCovid_Confirmed_Cases_as_pct <- log(raw$Covid_Confirmed_Cases_as_pct + 0.0001)
```

```{r}
# Base dataset of interest for this pset - data_ord_base
data_ord <- raw[raw$State_Name=="Florida", ]
data_ord <- data_ord[, c(2, 9, 12, 13, 14, 22)]

data_ord_base <- data_ord
data_ord_base$Covid_Confirmed_Cases_as_pct <- 100*data_ord_base$Covid_Confirmed_Cases_as_pct
data_ord_base$Always_Wear_Mask_Survey <- 100*data_ord_base$Always_Wear_Mask_Survey

data_ord_base1 <- data_ord_base
data_ord_base <- data_ord_base1[,-1]
rownames(data_ord_base) <- data_ord_base1[,1] # rownames are county names

dim(data_ord_base)
head(data_ord_base)
plot(data_ord_base)
```

inertia is like variance but for a two way variable; inertia is sum of eigenvalues (look at proportion explained to see how much is explained in first direction, etc./ cumulative, after third, 98% of degradation etc. )

```{r}
# Enviromental variables dataset - data_ord_env
data_ord_env_county <- raw[raw$State_Name=="Florida", ]
data_ord_env_county <- data_ord_env_county[, c(2, 10, 18, 19, 25, 15)]

data_ord_env <- data_ord_env_county
data_ord_env$Civilian_Labor_Force_2019_as_pct <- 100*data_ord_env$Civilian_Labor_Force_2019_as_pct

data_ord_env1 <- data_ord_env
data_ord_env <- data_ord_env1[,-1]
rownames(data_ord_env) <- data_ord_env1[,1] # rownames are county names

dim(data_ord_env)
head(data_ord_env)
```



# 1 

**Fit Correspondence Analysis to your data.**

All columns of `data_ord_base` contains the variable data. Correspondence analysis is performed using the `cca()` function.

```{r}
# No negative data anyways
# data_ord_base <- data_ord_base[apply(data_ord_base, 1, sum) > 0, ]

#Perform correspondence analysis
data_ord_base_ca <- cca(data_ord_base)

# inertia is measure of departure from ind model; if no relationships from rows and columns; in this case, household income, percent poverty are related; other variables are not so strongly related; if inertia smaller - less structure to data in 5-D 
```


# 2

**Discuss the inertia, make a two dimensional plot of the first two CA directions.**


```{r}
summary(data_ord_base_ca)
```


Inertia (equal to squared eigenvalues) is like variance and measures departures from the independence model. We see that the inertia value is 0.05033. The magnitude of inertia does not reflect more or less variance per se; it is reflective of the magnitude of the data. (Note that multiplying fractions by 100 to make values as percents did not increase this inertia magnitude).

In the "Proportion Explained" row, we can see that first CA direction explains 0.71649 (~72%) of the relation. The "Cumulative Proportion" by the second CA direction is 0.914297; hence, the first and second CA directions explain the vast majority of total inertia. The third and fourth CA directions have significantly smaller "Proportion Explained" values

```{r}
#plot results
plot(data_ord_base_ca, main = "Correspondence Analysis for FL Counties", type = "n")
text(data_ord_base_ca, dis = "wa", labels = rownames(data_ord_base))
points(data_ord_base_ca, pch = 21, col = "red", bg = "yellow", cex = 1.2)
text(data_ord_base_ca, "species", col = "blue", cex = 0.8)
```


Add environmental variables.

```{r}
plot(data_ord_base_ca, main = "Correspondence Analysis for FL Counties", type = "n")
points(data_ord_base_ca, pch = 19, col = "black", cex = 1)
text(data_ord_base_ca, "species", col = "blue", cex = 1.1)
#add environmental variables
fit <- envfit(data_ord_base_ca, data_ord_env, permutations = 1000)
plot(fit, col = "red", lwd = 3)
```

```{r}
#get significance - all environmental variables are significant
fit
```

We can see that all environmental variables are significant (p < 0.05) except `Birth_Rate_2019` and `Death_Rate_2019`. We will omit these variables from the environmental variable dataset for future analyses.

```{r}
data_ord_env <- subset(data_ord_env, select=-2)
data_ord_env <- subset(data_ord_env, select=-2)
```


This plot is somewhat hard to read, so we try detrended correspondence analysis. This is even harder to read. DCA uses the `decorana()` function.

```{r}
#detrended correspondence analysis
data_ord_base_dca <- decorana(data_ord_base)
plot(data_ord_base_dca, main = "DCA for Rural-Urban Type", type = "n")
text(data_ord_base_dca, display = c("sites"), labels = rownames(data_ord_base), cex = 0.86)
points(data_ord_base_dca, pch = 21, col = "red", bg = "yellow", cex = 0.6)
text(data_ord_base_dca, "species", col = "blue", cex = 0.6)

#add environmental variables
fit <- envfit(data_ord_base_dca, data_ord_env, permutations = 1000)
plot(fit, col = "red", lwd = 3)
```




# 3

**Comment on whether or not there is any evidence of 'data snaking' in higher dimensional space.**



# 4

**In a few sentences, describe what you conclude from your plot.**


# 5

**Perform Multidimensional Scaling (metric or non-metric) for 1, 2, and 3 dimensions.**

```{r, results="hide", warning=F, message=F}
results <- matrix(NA, 21, 5)
#j is number of dimensions to try
for (j in 1:5){
  for (i in 1:20){
    temp <- data_ord_base[shuffle(nrow(data_ord_base)), 1]
    for (k in 2:12) { temp <- cbind(temp, data_ord_base[shuffle(nrow(data_ord_base)), k]) }
    #store stress
    results[i, j] <- metaMDS(temp, k = j, distance = "euclidean")$stress
  }
  results[21, j] <- metaMDS(data_ord_base, k = j, distance = "euclidean")$stress
}

# Note: results are hidden (too long)
```

```{r}
#plot stress results

plot(c(1:5), results[21, ], type = "b", col = "blue", lwd = 3, 
     ylim = c(0, max(results)), xlab = "Dimensions", ylab = "Stress", pch = 19, 
     main = "MDS for Rural-Urban Data, Euclidean Distance")
mins <- apply(results[1:20, ], 2, min)
maxs <- apply(results[1:20, ], 2, max)
meds <- apply(results[1:20, ], 2, median)

for (i in 1:5){
  points(rep(i, 3), c(mins[i], meds[i], maxs[i]), type = "b", col = "red", lwd = 3, pch = 19)
}
legend(3.5, (.9*max(results)), c("MDS Solution", "20 Permutations"), lwd = 3, col = c("blue", "red"))
```

After performing multidimensional scaling for 1-5 dimensions, the above scree plot for stress illustrates an elbow at 2 dimensions.

*Probably can add more explanation here*



# 6

**Discuss the stress (or SStress) of each dimensional solution. Make a scree plot if you're able.**


# 7

**Make a two dimensional plot of your MDS results.**

```{r}
data_ord_base.mds2 <- metaMDS(data_ord_base, k = 2, distance = "euclidean")
plot(data_ord_base.mds2, type = "t")
```

```{r}
#more refined plot
fig <- ordiplot(data_ord_base.mds2, type = "none", cex = 1.1)
text(fig, "species", col = "red", cex = 1.1)
text(fig, "sites", col = "blue", cex = 0.8)
```

We can also add environmental variables to our plot.

```{r}
fig <- ordiplot(data_ord_base.mds2, type = "none", cex = 1.1)
text(fig, "species", col = "red", cex = 1.1)
text(fig, "sites", col = "blue", cex = 0.8)

fit <- envfit(data_ord_base.mds2, data_ord_env, permutations = 1000)
plot(fit, col = "black", lwd = 3)
```


# 8

**If possible, overlay some other continuous variable(s) to interpret your ordination axes. Calculate p-values for the overlaid additional variable(s). If you can, get some non-linear wireplots of the these overlaid variables (see examples online in R).**




# 9

**Again, assuming you have at least one additional continuous variable, perform canonical correspondence analysis.**





# 10

**Finally, write a paragraph or so comparing the methods you’ve used, discuss what conclusions you reach, etc.**


